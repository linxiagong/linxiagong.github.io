<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on GONG Linxia</title><link>https://linxiagong.github.io/series/large-language-models/</link><description>Recent content in Large Language Models on GONG Linxia</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy; 2021 &lt;a href="https://www.wangchucheng.com/">WANG Chucheng&lt;/a> and &lt;a href="https://www.ruiqima.com/">MA Ruiqi&lt;/a></copyright><lastBuildDate>Mon, 31 Jul 2023 17:59:04 +0800</lastBuildDate><atom:link href="https://linxiagong.github.io/series/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>[WIP] Building Multilingual Parallel Corpus</title><link>https://linxiagong.github.io/posts/gpt/build-multilingual-parallel-corpus/</link><pubDate>Mon, 31 Jul 2023 17:59:04 +0800</pubDate><guid>https://linxiagong.github.io/posts/gpt/build-multilingual-parallel-corpus/</guid><description>I am joining a new project about language models and my primary focus is on constructing parallel corpora across languages.
Multilingual LLM Multilingual Capability of LLM ChatGPT is not a perfect multilingual model Illustrated comparison of 200 languages translated from English into various target languages, sorted by their language scores in ChrF++ for ChatGPT. Source: (Lu et al. 2023) Related Work As I progress with this project, I am documenting noteworthy related works for future references.</description></item></channel></rss>